{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as sd\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.metrics as sm  # 评估模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据集\n",
    "data = sd.load_files('./data/20news', encoding='latin1', random_state=7)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2968"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.data)  # 2968封邮件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('From: gene@theporch.raider.net (Gene Wright)\\nSubject: NASA Special Publications for Voyager Mission?\\nOrganization: The MacInteresteds of Nashville, Tn.\\nLines: 12\\n\\nI have two books, both NASA Special Publications, on the Voyager \\nMissions. One is titled \"Voyages to Jupiter\" the other \"Voyage to Saturn\" \\nThese were excellent books put together after the encounters with each \\nplanet. \\n\\nThe question is: Did NASA ever put together a similar book for either the \\nUranus encounter or Neptune? If so, what SP number is it and where can it \\nbe obtained? If not, why didn\\'t they?\\n\\n--\\n  gene@theporch.raider.net (Gene Wright)\\ntheporch.raider.net  615/297-7951 The MacInteresteds of Nashville\\n',\n",
       " 4,\n",
       " 'sci.space')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[0], data.target[0], data.target_names[4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**逻辑回归测试和引入朴素贝叶斯**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9354517048605283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.78      0.86       131\n",
      "           1       0.93      0.97      0.95       122\n",
      "           2       0.96      0.99      0.97       110\n",
      "           3       0.89      0.98      0.93       121\n",
      "           4       0.97      0.99      0.98       110\n",
      "\n",
      "    accuracy                           0.94       594\n",
      "   macro avg       0.94      0.94      0.94       594\n",
      "weighted avg       0.94      0.94      0.94       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_extraction.text as ft\n",
    "# 整理输入集与输出集  TFIDF\n",
    "cv = ft.CountVectorizer()\n",
    "bow = cv.fit_transform(data.data)\n",
    "tt = ft.TfidfTransformer()\n",
    "tfidf = tt.fit_transform(bow)\n",
    "\n",
    "# 拆分测试集与训练集\n",
    "train_x, test_x, train_y, test_y = ms.train_test_split(tfidf, data.target, test_size=0.2, random_state=7)\n",
    "\n",
    "# 交叉验证\n",
    "model = lm.LogisticRegression()\n",
    "\n",
    "# 使用朴素贝叶斯\n",
    "import sklearn.naive_bayes as nb\n",
    "model = nb.MultinomialNB()\n",
    "score = ms.cross_val_score(model, train_x, train_y, cv=5, scoring='f1_weighted')\n",
    "print(score.mean())\n",
    "\n",
    "# 训练模型\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# 测试模型，评估模型\n",
    "pred_test_y = model.predict(test_x)\n",
    "print(sm.classification_report(test_y, pred_test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**整理一组测试样本进行模型测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "new_data = [\"At the last game, a spectator was hit by a baseball and was hospitalized. \",\n",
    "        \"Recently, Lao Wang is working on asymmetric encryption algorithms. \",\n",
    "        \"The two-wheeled car runs well on the highway. \",\n",
    "        \"Next year, China will explore Mars. \"]\n",
    "# 把样本按照训练时的方式转换为tfidf矩阵，才可以交给模型\n",
    "bow = cv.transform(new_data)\n",
    "test_data = tt.transform(bow)\n",
    "pred_test_y = model.predict(test_data)\n",
    "print(pred_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['misc.forsale',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.crypt',\n",
       " 'sci.space']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd16a1c2e981052eaae61151b9525ae9913f1f0d16bca6b7e7be9e0f29d739d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
